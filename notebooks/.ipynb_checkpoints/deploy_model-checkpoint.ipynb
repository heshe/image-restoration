{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24721174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.28.0 to work with mlops\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35d79e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/gpu-mlops/code/Users/s147056/image-restoration\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get experiment folder\n",
    "experiment_folder = Path(os.getcwd()).parent.parent\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "808f61e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_resto version 2\n"
     ]
    }
   ],
   "source": [
    "model = ws.models['image_resto']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16587c1",
   "metadata": {},
   "source": [
    "## Create yaml for env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dead86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dependency info in /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpu-mlops/code/Users/s147056/image-restoration/src/deploy/image_resto_env.yml\n",
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - azureml-defaults\n",
      "\n",
      "  - \"click\\n\"\n",
      "  - \"Sphinx\\n\"\n",
      "  - \"coverage\\n\"\n",
      "  - \"awscli\\n\"\n",
      "  - \"flake8\\n\"\n",
      "  - \"python-dotenv>=0.5.1\\n\"\n",
      "  - \"wandb\\n\"\n",
      "  - \"pathlib2\\n\"\n",
      "  - \"argparse\\n\"\n",
      "  - \"torch\\n\"\n",
      "  - \"torchvision\\n\"\n",
      "  - \"opencv-python\\n\"\n",
      "  - joblib\n",
      "channels:\n",
      "- anaconda\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "# Ensure the required packages are installed (we need pip, scikit-learn and Azure ML defaults)\n",
    "packages = CondaDependencies()\n",
    "\n",
    "# Add pip packages from requirements.txt\n",
    "with open(os.path.join(experiment_folder, \"requirements.txt\"), \"r\") as f:\n",
    "    for line in f:\n",
    "        if line[0].isalpha():\n",
    "            packages.add_pip_package(line)\n",
    "            \n",
    "# Save the environment config as a .yml file\n",
    "env_file = os.path.join(experiment_folder, \"src\", \"deploy\", \"image_resto_env.yml\")\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(packages.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)\n",
    "\n",
    "# Print the .yml file\n",
    "with open(env_file,\"r\") as f:\n",
    "    print(f.read())           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b79f88",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dedbdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-06-15 18:56:50+00:00 Creating Container Registry if not exists.\n",
      "2021-06-15 18:56:50+00:00 Registering the environment.\n",
      "2021-06-15 18:56:51+00:00 Building image."
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core import Model\n",
    "\n",
    "# Set path for scoring script\n",
    "script_file = os.path.join(experiment_folder, \"src\", \"deploy\", \"deploy_model.py\")\n",
    "\n",
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                   entry_script=script_file,\n",
    "                                   conda_file=env_file)\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "\n",
    "service_name = \"image-reconstruction-service\"\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d343aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for webservice_name in ws.webservices:\n",
    "    print(webservice_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e39fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_new = torch.rand(1, 224, 224)*255\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
    "reconstruction = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted class - it'll be the first (and only) one.\n",
    "reconstruction = json.loads(reconstruction)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "type(reconstruction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
