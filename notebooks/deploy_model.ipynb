{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f99458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.28.0 to work with mlops\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcac22bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/gpu-mlops/code/Users/s147056/image-restoration\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get experiment folder\n",
    "experiment_folder = Path(os.getcwd()).parent\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1689402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_resto version 2\n"
     ]
    }
   ],
   "source": [
    "model = ws.models['image_resto']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c4e7c",
   "metadata": {},
   "source": [
    "## Create yaml for env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81aaac9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dependency info in /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpu-mlops/code/Users/s147056/image-restoration/src/deploy/image_resto_env.yml\n",
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - azureml-defaults\n",
      "\n",
      "  - click\n",
      "  - Sphinx\n",
      "  - coverage\n",
      "  - awscli\n",
      "  - flake8\n",
      "  - python-dotenv>=0.5.1\n",
      "  - wandb\n",
      "  - pathlib2\n",
      "  - argparse\n",
      "  - torch\n",
      "  - torchvision\n",
      "  - opencv-python\n",
      "  - joblib\n",
      "channels:\n",
      "- anaconda\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "# Ensure the required packages are installed (we need pip, scikit-learn and Azure ML defaults)\n",
    "packages = CondaDependencies()\n",
    "\n",
    "# Add pip packages from requirements.txt\n",
    "with open(os.path.join(experiment_folder, \"requirements.txt\"), \"r\") as f:\n",
    "    for line in f:\n",
    "        if line[0].isalpha():\n",
    "            packages.add_pip_package(line.strip())\n",
    "            \n",
    "# Save the environment config as a .yml file\n",
    "env_file = os.path.join(experiment_folder, \"src\", \"deploy\", \"image_resto_env.yml\")\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(packages.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)\n",
    "\n",
    "# Print the .yml file\n",
    "with open(env_file,\"r\") as f:\n",
    "    print(f.read())           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b69172",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a864679c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-06-15 20:10:02+00:00 Creating Container Registry if not exists.\n",
      "2021-06-15 20:10:02+00:00 Registering the environment.\n",
      "2021-06-15 20:10:04+00:00 Use the existing image.\n",
      "2021-06-15 20:10:04+00:00 Generating deployment configuration.\n",
      "2021-06-15 20:10:05+00:00 Submitting deployment to compute..\n",
      "2021-06-15 20:10:11+00:00 Checking the status of deployment image-reconstruction-service..\n",
      "2021-06-15 20:13:50+00:00 Checking the status of inference endpoint image-reconstruction-service.\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Service deployment polling reached non-successful terminal state, current service state: Failed\n",
      "Operation ID: 7fbc26ad-d0a9-4b8a-8d11-74bcee4d7e19\n",
      "More information can be found using '.get_logs()'\n",
      "Error:\n",
      "{\n",
      "  \"code\": \"AciDeploymentFailed\",\n",
      "  \"statusCode\": 400,\n",
      "  \"message\": \"Aci Deployment failed with exception: Error in entry script, ModuleNotFoundError: No module named 'src', please run print(service.get_logs()) to get details.\",\n",
      "  \"details\": [\n",
      "    {\n",
      "      \"code\": \"CrashLoopBackOff\",\n",
      "      \"message\": \"Error in entry script, ModuleNotFoundError: No module named 'src', please run print(service.get_logs()) to get details.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 7fbc26ad-d0a9-4b8a-8d11-74bcee4d7e19\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Error in entry script, ModuleNotFoundError: No module named 'src', please run print(service.get_logs()) to get details.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Error in entry script, ModuleNotFoundError: No module named 'src', please run print(service.get_logs()) to get details.\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 7fbc26ad-d0a9-4b8a-8d11-74bcee4d7e19\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Error in entry script, ModuleNotFoundError: No module named 'src', please run print(service.get_logs()) to get details.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Error in entry script, ModuleNotFoundError: No module named 'src', please run print(service.get_logs()) to get details.\\\"\\n    }\\n  ]\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1af83a23bc92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mservice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeployment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output, timeout_sec)\u001b[0m\n\u001b[1;32m    921\u001b[0m                                           \u001b[0;34m'Error:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                                           '{}'.format(self.state, self._operation_endpoint.split('/')[-1],\n\u001b[0;32m--> 923\u001b[0;31m                                                       logs_response, format_error_response), logger=module_logger)\n\u001b[0m\u001b[1;32m    924\u001b[0m             print('{} service creation operation finished, operation \"{}\"'.format(self._webservice_type,\n\u001b[1;32m    925\u001b[0m                                                                                   operation_state))\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 7fbc26ad-d0a9-4b8a-8d11-74bcee4d7e19\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Error in entry script, ModuleNotFoundError: No module named 'src', please run print(service.get_logs()) to get details.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Error in entry script, ModuleNotFoundError: No module named 'src', please run print(service.get_logs()) to get details.\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 7fbc26ad-d0a9-4b8a-8d11-74bcee4d7e19\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Error in entry script, ModuleNotFoundError: No module named 'src', please run print(service.get_logs()) to get details.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Error in entry script, ModuleNotFoundError: No module named 'src', please run print(service.get_logs()) to get details.\\\"\\n    }\\n  ]\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core import Model\n",
    "\n",
    "# Set path for scoring script\n",
    "script_file = os.path.join(experiment_folder, \"src\", \"deploy\", \"deploy_model.py\")\n",
    "\n",
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                   entry_script=script_file,\n",
    "                                   conda_file=env_file)\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "\n",
    "service_name = \"image-reconstruction-service\"\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20708db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-15T20:14:21,381043400+00:00 - rsyslog/run \n",
      "2021-06-15T20:14:21,379546000+00:00 - iot-server/run \n",
      "2021-06-15T20:14:21,379547900+00:00 - gunicorn/run \n",
      "2021-06-15T20:14:21,400435700+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-06-15T20:14:21,684239100+00:00 - iot-server/finish 1 0\n",
      "2021-06-15T20:14:21,686507000+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (158)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 187\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-06-15 20:14:25,935 | root | INFO | Starting up app insights client\n",
      "2021-06-15 20:14:25,935 | root | INFO | Starting up request id generator\n",
      "2021-06-15 20:14:25,936 | root | INFO | Starting up app insight hooks\n",
      "2021-06-15 20:14:25,936 | root | INFO | Invoking user's init function\n",
      "2021-06-15 20:14:25,942 | root | ERROR | User's init function failed\n",
      "2021-06-15 20:14:25,943 | root | ERROR | Encountered Exception Traceback (most recent call last):\n",
      "  File \"/var/azureml-server/aml_blueprint.py\", line 182, in register\n",
      "    main.init()\n",
      "  File \"/var/azureml-app/deploy_model.py\", line 12, in init\n",
      "    model = joblib.load(model_path)\n",
      "  File \"/azureml-envs/azureml_aa5891be7be789109b4b4b718c34e5a7/lib/python3.6/site-packages/joblib/numpy_pickle.py\", line 585, in load\n",
      "    obj = _unpickle(fobj, filename, mmap_mode)\n",
      "  File \"/azureml-envs/azureml_aa5891be7be789109b4b4b718c34e5a7/lib/python3.6/site-packages/joblib/numpy_pickle.py\", line 504, in _unpickle\n",
      "    obj = unpickler.load()\n",
      "  File \"/azureml-envs/azureml_aa5891be7be789109b4b4b718c34e5a7/lib/python3.6/pickle.py\", line 1050, in load\n",
      "    dispatch[key[0]](self)\n",
      "  File \"/azureml-envs/azureml_aa5891be7be789109b4b4b718c34e5a7/lib/python3.6/pickle.py\", line 1338, in load_global\n",
      "    klass = self.find_class(module, name)\n",
      "  File \"/azureml-envs/azureml_aa5891be7be789109b4b4b718c34e5a7/lib/python3.6/pickle.py\", line 1388, in find_class\n",
      "    __import__(module, level=0)\n",
      "ModuleNotFoundError: No module named 'src'\n",
      "\n",
      "2021-06-15 20:14:25,943 | root | INFO | Waiting for logs to be sent to Application Insights before exit.\n",
      "2021-06-15 20:14:25,943 | root | INFO | Waiting 30 seconds for upload.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "508febab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for webservice_name in ws.webservices:\n",
    "    print(webservice_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad761ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_new = torch.rand(1, 224, 224)*255\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
    "reconstruction = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted class - it'll be the first (and only) one.\n",
    "reconstruction = json.loads(reconstruction)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "type(reconstruction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
